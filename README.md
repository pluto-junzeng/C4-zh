# C4-zh

随着预训练模型发展，中文预训练模型对于学术界和工业界更加重要，我们从C4 以及其他公开的数据集中中文自然语言推理数据集，从而构建大规模高质量的中文预训练语料

#### 数据来源

| 数据来源 | 数据规模                       | 大小 | 链接 |
| -------- | ------------------------------ | ---- | ---- |
| 搜狐新闻 | 2008~2019 共计100w条  |   12G    |      |
| 百度知道     |      60万条              |  3G |     |
|  百度搜索       |     60万条                           |   3G   |      |
| 新浪新闻 | 2008~2019滚动新闻  共计 10w条              |   2G   |      |
| 百度百科    |      2012年百度百科 ,400w词条             |  22G  |      |
|百度百科|2019年百度百科，500w条|50G|不提供下载，[下载教程(https://blog.csdn.net/u013741019/article/details/102882731)]|
| 清华新闻       |    86万条                            |  4G    |      |
| 维基中文       |    50万条                            |  2G    |      |


#### Reference

大规模中文自然语言处理语料 Large Scale Chinese Corpus for NLP  https://github.com/brightmart/nlp_chinese_corpus

